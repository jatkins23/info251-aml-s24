{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aa683ef",
   "metadata": {},
   "source": [
    "# Problem Set 6: Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4a6bae",
   "metadata": {},
   "source": [
    "\n",
    "<span style=\"color:red\">Warning!</span> Some of the problems in this problem set require heavy computation - you are encouraged to start early so that you don't get stuck at the last minute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1511ff6c",
   "metadata": {},
   "source": [
    "# Section 1: Neural Network Architecture\n",
    "\n",
    "In the first section of this problem set, we'll spend some time examining neural network model architecture. Please type in your answers after each question -- this section requires no coding.\n",
    "\n",
    "### Question 1.1\n",
    "\n",
    "Consider an input image of dimensions 150 X 150 X 3: i.e., height and width of 150 pixels, with 3 channels. \n",
    "\n",
    "- 1.1.1 Suppose you feed this image into a fully connected (dense) layer with 512 neurons. How many learnable / trainable parameters (or weights) does this layer have?\n",
    "    \n",
    "- 1.1.2 Now, suppose we feed this image into a Conv2D layer with 512 filters, kernel size 3 x 3, and stride 1 (assume 0 padding). How many learnable / trainable parameters (or weights) does this layer have?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece0fa57",
   "metadata": {},
   "source": [
    "#### Your Answer Here\n",
    "\n",
    "1.1.1: \n",
    "\n",
    "1.1.2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb08e6a2",
   "metadata": {},
   "source": [
    "### Question 1.2\n",
    "\n",
    "Consider the following CNN, and answer the related questions. Assume that your input images are of dimensions (150, 150, 3): i.e., height and width of 150 pixels, with 3 channels.\n",
    "\n",
    "**1.2.1**: Complete the table -- fill in the missing entries (A, B, C, D). For each missing entry, provide a brief explanation for your answer (No more than 2 brief sentences.)\n",
    "\n",
    "- Hint: The Keras documentation [MaxPooling2D](https://keras.io/api/layers/pooling_layers/max_pooling2d/) will be of use\n",
    "\n",
    "![Model image](images/model1-verbose.png)\n",
    "\n",
    "**1.2.2**: Report the total number of parameters in this model?\n",
    "\n",
    "**1.2.3**: Consider Layer 2 from above. Suppose we change the stride to 2, how does it affect the output shape (A) that you calculated above? How does it affect the number of parameters (B)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd8c4e7",
   "metadata": {},
   "source": [
    "#### Your Answer Here\n",
    "\n",
    "**1.2.1**:\n",
    "\n",
    "\n",
    "**1.2.2**:\n",
    "\n",
    "\n",
    "    \n",
    "**1.2.3**:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d5bda4",
   "metadata": {},
   "source": [
    "# Section 2: Truck v/s Cars: Neural Networks and Image Classification\n",
    "\n",
    "Your goal for this problem set is to train neural network models for image classification. Specifically, your task is to train models that correctly predict where the vehicle in a given image is a truck, or a car / automobile.\n",
    "\n",
    "It might be useful to start by implementing this entire problem set on a relatively small subset of all of the images first, before using the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c098a7e3",
   "metadata": {},
   "source": [
    "## 2.1. Load Data +  Exploratory Analysis\n",
    "\n",
    "For this problem, we'll load the [CIFAR 10](https://keras.io/api/datasets/cifar10/) dataset, from the Keras API. This dataset has been widely used in ML and computer vision research -- you can read more about the state of the art model performance (and how this has improved over time) [here](https://en.wikipedia.org/wiki/CIFAR-10).\n",
    "\n",
    "The CIFAR 10 dataset originally has 10 classes -- we've provided helper code below to load the data, and remove images belonging to unnecessary classes. We will use this dataset for a supervised binary classification problem.\n",
    "\n",
    "Your tasks:\n",
    " - Extract a validation set from your training data. Keep 70% of the images for training, while the remainder will be used for validation. \n",
    " - Examine a single image in from your training set. Report the dimensions (width, height, number of channels.) Plot each channel.\n",
    " - Select 9 random images from your training set. Plot these images in a 3 X 3 grid, along with the corresponding category / label\n",
    " - Plot the distribution of labels in your training, validation and test sets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "144aba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "def cifar_2classes():\n",
    "    \"\"\"\n",
    "    Helper code to clean the CIFAR 10 dataset, and remove the unnecessary classes. \n",
    "    \"\"\"\n",
    "    ## Load data\n",
    "    label_names = [\"airplane\", \n",
    "             \"automobile\",\n",
    "             \"bird\",\n",
    "             \"cat\",\n",
    "             \"deer\",\n",
    "             \"dog\",\n",
    "             \"frog\",\n",
    "             \"horse\",\n",
    "             \"ship\",\n",
    "             \"truck\"]\n",
    "\n",
    "\n",
    "    label_map = {0:99, 1:0, 2:99, 3:99, 4:99, 5:99, 6:99, 7:99, 8:99, 9:1}\n",
    "    \n",
    "    (X_train_val, y_train_val), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "    (X_train_val, y_train_val), (X_test, y_test) = cifar10.load_data()\n",
    "    y_train_val1 = np.array([[label_map[y[0]]] for y in y_train_val])\n",
    "    y_test1 = np.array([[label_map[y[0]]] for y in y_test])\n",
    "    \n",
    "    X_train_val_clean = X_train_val[np.where(y_train_val1 != 99)[0]]\n",
    "    y_train_val_clean =  y_train_val1[np.where(y_train_val1 != 99)]\n",
    "    \n",
    "    X_test_clean = X_test[np.where(y_test1 != 99 )[0]]\n",
    "    y_test_clean = y_test1[np.where(y_test1 != 99)]\n",
    "    \n",
    "    return X_train_val_clean, y_train_val_clean, X_test_clean, y_test_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd6af764",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data\n",
    "X_train_val, y_train_val, X_test, y_test = cifar_2classes()\n",
    "\n",
    "## Split into train, validation and test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f574b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb33886a",
   "metadata": {},
   "source": [
    "## 2.2 Preprocessing\n",
    " \n",
    "- Rescale the images data, so that the values lie between a range of 0 and 1. \n",
    "- Hint: A simple way to do this is to divide by 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fbb2efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b54c10e",
   "metadata": {},
   "source": [
    "## 2.3 Feedforward Neural Network\n",
    "\n",
    "Reshape your data so that each image is flattened into a 1d array, and each of the train, test and validation sets are 2d arrays. \n",
    "\n",
    "Essentially, your data should be an array of length N, where N is the number of observations (images) in the train / test / validation sets. Each element in the array is a flattened image, of length 3072 (32 X 32 X3)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e2a52f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0430d32d",
   "metadata": {},
   "source": [
    "\n",
    "### 2.3.1 Build a neural network with the following parameters\n",
    "\n",
    "  - Architecture\n",
    "     - Input dimensions: 3072 \n",
    "     - 1 hidden layer: 64 nodes, Relu activation\n",
    "     - Output layer: 1 node, Sigmoid activation\n",
    " - Compile the network:\n",
    "     - Optimizer: Adam\n",
    "     - Epochs: 30\n",
    "     - Batch size: 32\n",
    "     - Metrics: Accuracy\n",
    "     - Remember to include the validation data in the compilation step. \n",
    "  - Outputs:\n",
    "      - Plot the training and validation accuracy by epoch (See the example plot below). Do you see any evidence of overfitting in your plot?\n",
    "      - Report the accuracy, Precision and Recall on the test set\n",
    "      \n",
    "**Example plot**\n",
    "\n",
    "![ffn_performance](images/example_plot_ffn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3ad4863",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da7b27b",
   "metadata": {},
   "source": [
    "### 2.3.2. Tuning / Improving Performance\n",
    "\n",
    "Now, go ahead and tune this network, or write up your own from scratch. The goal should be to exceed 75% overall classification accuracy on the test set. We don't expect you to implement cross-validation or any formal hyperparameter optimization techniques. Rather, the goal is to arrive at a model architecture that's acceptable to you via trial and error.  \n",
    "\n",
    "Remember that you have a number of hyperparameters to work with, including\n",
    "  - the number / dimension of hidden layers\n",
    "  - choice of activation functions, \n",
    "  - type regularization, \n",
    "  - optimization techniques \n",
    "  \n",
    "Note that you shouldn't need to train your model for more than 30 epochs.\n",
    "  \n",
    "The notebooks from Labs 9 and 10 are also a good starting point.\n",
    "  \n",
    " \n",
    "**Outputs:**\n",
    "- In 2-3 sentences, briefly explain the various choices/ decisions you made in building your model architecture. \n",
    "- Report the classification accuracy on the test set, along with the precision and recall for each class.\n",
    "- What do you notice about the precision and recall values, as well as the overall classification accuracy, in comparison to your outputs from 2.3.1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a88a8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5ad91b",
   "metadata": {},
   "source": [
    "## 2.4. Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4105d258",
   "metadata": {},
   "source": [
    "\n",
    "### 2.4.1. Build a CNN with the following parameters\n",
    "\n",
    "  - Architecture\n",
    "     - Input dimensions: (32, 32,  3) \n",
    "     - 1 Conv2D Layer: \n",
    "         - Number of filters: 20. \n",
    "         - Filter Dimension: 3 X 3. \n",
    "         - Activation: Relu\n",
    "     - Flatten\n",
    "     - Output layer: 1 node, Sigmoid activation\n",
    " - Compile the network:\n",
    "     - Optimizer: Adam\n",
    "     - Epochs: 20\n",
    "     - Metrics: Accuracy\n",
    "     - Remember to include the validation data in the compilation step. \n",
    "  - Outputs:\n",
    "      - Plot the training and validation accuracy by epoch.\n",
    "      - Report the accuracy, Precision and Recall on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c4751d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your Code Here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e23532c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e356c3e1",
   "metadata": {},
   "source": [
    "### 2.4.2. Tuning / Improving Performance\n",
    "\n",
    "Now, go ahead and tune this network, or write up your own from scratch. The goal should be to exceed 85% overall classification accuracy on the test set. We don't expect you to implement cross-validation or any formal hyperparameter optimization techniques. Rather, the goal is to arrive at a model architecture that's acceptable to you via trial and error. \n",
    "\n",
    "Note that you shouldn't need to train your model for more than 30 epochs. \n",
    "\n",
    "Remember that you have a number of hyperparameters to work with, including\n",
    "  - the number / dimension of hidden layers\n",
    "  - choice of activation functions, \n",
    "  - type regularization, \n",
    "  - optimization techniques\n",
    "  - and other relevant aspects(adding data augmentation etc.)\n",
    "  \n",
    "The notebooks from Labs 9 and 10 are a good starting point in terms of putting together a more complex architecture. \n",
    "\n",
    "<span style=\"color:red\">Warning!</span> If you intend to attempt **Extra Credit 1 and 2** (below), ensure that you carefully name / store the trained model you build in this step. It's fine to keep trained model in memory, or to save the weights to disk.\n",
    "\n",
    "  \n",
    " \n",
    "**Outputs:**\n",
    " - Report the classification accuracy on the test set, along with the precision and recall for each class. \n",
    " - Briefly explain your model architecture / choices you made in tuning your CNN (No more than 3 - 4 sentences)\n",
    " - What do you notice about the precision and recall values, as well as the overall classification accuracy, in comparison to the feed forward neural networks from part 2.3, and your baseline in 2.4.1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3de7e05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82ad71f",
   "metadata": {},
   "source": [
    "### 2.5: Convolutional Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1375d37c",
   "metadata": {},
   "source": [
    "Now, let's attempt to better understand what our CNN is doing under the hood. We'll start by visually examining our convolutional filters. \n",
    "\n",
    "- We'll focus on the first convolutional layer in your CNN. \n",
    "    - Use the [get_weights()](https://keras.io/api/layers/base_layer/#getweights-method) method to obtain the filters.\n",
    "    - Plot the first 5 filters, for each channel (your plot will be a grid of 5 X 3). \n",
    "    - Your plot will resemble the one below (the exact nature of the visual patterns will depend on your model architecture etc.)\n",
    "    - What do you observe about the filters you visualize? \n",
    "    \n",
    "**Example output**\n",
    " ![Example](images/filters.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec0e393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f7edd5",
   "metadata": {},
   "source": [
    "### Extra Credit 1: Feature Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1e04d2",
   "metadata": {},
   "source": [
    "A feature map, or an activation map allows us to examine the result of applying the filters to a given input. The broad intuition is that feature maps closer to the input image detect fine-grained detail, whereas feature maps closer to the output of the model capture more generic aspects. \n",
    "\n",
    "Your task is to create and visualize a feature map (i.e the outputs) from the first convolutional layer in your trained CNN. \n",
    "\n",
    "In order to do this, proceed as follows:\n",
    "- Identify a nice image from your training data -- ideally, something that has some distinguishing properties to the naked eye.\n",
    "- Pass this image through your trained CNN from **2.4.2**, and store the output from the first convolutional layer -- this is your feature map! Note that there are multiple ways to do this; the simplest is to create a copy of your trained CNN, and remove the later layers. The Models function can help you do this. \n",
    "- Note that the size of the feature map depends on how many filters you have in the layer. \n",
    "- Outputs:\n",
    "    - plot 1) The raw image from the training data, and 2) the feature map. An example is shown below:\n",
    "    - what do you observe about the feature maps?\n",
    "    \n",
    "**Raw Image**\n",
    "![Plane](images/plane1.png)\n",
    "\n",
    "**Feature Map**\n",
    "![Plane-features](images/plane_feature_map.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "645dfed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "# First, store the inputs / outputs from the first convolutional / hidden layer in your network.\n",
    "# Hint: The keras documentation will be helpful (https://keras.io/guides/functional_api/)\n",
    "# Note that you can create a model using another model/ layer's inputs / outputs:\n",
    "# model = keras.Model(inputs=inputs, outputs=outputs, name=\"mnist_model\")\n",
    "\n",
    "# Then, pass your chosen image through(i.e predict)\n",
    "\n",
    "\n",
    "## Plot the original image, and the feature maps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba83ab5",
   "metadata": {},
   "source": [
    "### Extra Credit 2: Transfer Learning / Fine tuning\n",
    "\n",
    "\n",
    "Suppose you have a slightly different classification task at hand: to correctly separate trucks from airplanes. \n",
    "\n",
    "We'll examine how we can use an already trained model to do this, instead of coding up a new neural network from scratch. \n",
    "\n",
    "You are required to implement two approaches:\n",
    "\n",
    "- First, we'll use the CNN from D2 above -- and simply update the weights.\n",
    "- Second, we'll load a pre-trained model from keras/ tensorflow (e.g. ResNet50, or VGG19). While these models haven't seen the exact images in this dataset, they have been trained on a large general corpus. Since these models have millions of weights, so we'll implement the following approach:\n",
    "    - Load a pre-trained model\n",
    "    - Freeze the weights by setting trainable = False.\n",
    "    - Build a new model by adding additional layers to the base model.\n",
    "    - Train the new model and evaluate performance.\n",
    "    \n",
    "- Compare the performance of both approaches, and briefly summarize your observations\n",
    " \n",
    "We have provided some helper code and hints in the cells below. \n",
    "    \n",
    "<span style=\"color:red\">Warning!</span> Note that the second approach could be slow / time-consuming. If you are attempting it, please ensure that you budget ~20 mins to 1hour (worst case) for the code to complete running for this part. \n",
    "\n",
    "This is a handy reference: https://keras.io/guides/transfer_learning/#transfer-learning-amp-finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3e2c3c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifar_2moreclasses(pos_class, neg_class):\n",
    "    \"\"\"\n",
    "    Helper code to clean the CIFAR 10 dataset, and remove the unnecessary classes. \n",
    "    \"\"\"\n",
    "    ## Load data\n",
    "    label_names = [\"airplane\", \n",
    "             \"automobile\",\n",
    "             \"bird\",\n",
    "             \"cat\",\n",
    "             \"deer\",\n",
    "             \"dog\",\n",
    "             \"frog\",\n",
    "             \"horse\",\n",
    "             \"ship\",\n",
    "             \"truck\"]\n",
    "\n",
    "\n",
    "    label_map = {i:99 for i in range(len(label_names))}\n",
    "    label_map[pos_class] = 1\n",
    "    label_map[neg_class] = 0\n",
    "    \n",
    "    (X_train_val, y_train_val), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "    (X_train_val, y_train_val), (X_test, y_test) = cifar10.load_data()\n",
    "    y_train_val1 = np.array([[label_map[y[0]]] for y in y_train_val])\n",
    "    y_test1 = np.array([[label_map[y[0]]] for y in y_test])\n",
    "    \n",
    "    X_train_val_clean = X_train_val[np.where(y_train_val1 != 99)[0]]\n",
    "    y_train_val_clean =  y_train_val1[np.where(y_train_val1 != 99)]\n",
    "    \n",
    "    X_test_clean = X_test[np.where(y_test1 != 99 )[0]]\n",
    "    y_test_clean = y_test1[np.where(y_test1 != 99)]\n",
    "    \n",
    "    return X_train_val_clean, y_train_val_clean, X_test_clean, y_test_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8fa04e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 32, 32, 3) (3000, 32, 32, 3) (2000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "## Load data\n",
    "X_train_val1, y_train_val1, X_test1, y_test1 = cifar_2moreclasses(9, 0)\n",
    "\n",
    "## Split into train, validation and test.\n",
    "N_train, N_validation, N_test = 7000, 3000, 2000\n",
    "\n",
    "X_train1 = X_train_val1[:N_train,:,:]\n",
    "y_train1 = y_train_val1[:N_train]\n",
    "\n",
    "X_val1 = X_train_val1[N_train: N_train + N_validation,:,:]\n",
    "y_val1 = y_train_val1[N_train: N_train + N_validation]\n",
    "\n",
    "X_test1 = X_test1[:N_test]\n",
    "y_test1 = y_test1[:N_test]\n",
    "\n",
    "print(X_train1.shape, X_val1.shape, X_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0506deaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### APPROACH 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17a1c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import clone_model\n",
    "\n",
    "# Helper Code: Cloning the model (Edit the line below with the name of your model from D2)\n",
    "model_cnn3 = clone_model( model_from_D2 )\n",
    "\n",
    "# To do: Compile the model\n",
    "\n",
    "# To do: Copy weights from model_from_D2. \n",
    "#Reference: https://keras.io/2.15/api/models/model_saving_apis/weights_saving_and_loading/\n",
    "\n",
    "\n",
    "# To do: Preprocess the data\n",
    "\n",
    "# To do: Train this model (10 epochs)\n",
    "\n",
    "\n",
    "#To do: Evaluate performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b30c558",
   "metadata": {},
   "outputs": [],
   "source": [
    "### APPROACH 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d35e99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Helper code: load pre-trained model. Feel free to load something else. \n",
    "## Available options can be found here: https://keras.io/api/applications/#keras-applications\n",
    "\n",
    "from keras.applications import ResNet50\n",
    "base_model_1 = ResNet50(include_top = False, weights='imagenet',input_shape=(32,32,3))\n",
    "\n",
    "## To Do: Freeze the weights\n",
    "\n",
    "\n",
    "## Now initialize a new model -- add the pre-trained weights, along with some additional layers. \n",
    "# Hint / helper code -- here's one way to do this, but feel free to use your own. \n",
    "# model_1= Sequential()\n",
    "# model_1.add(base_model_1)\n",
    "# model_1.add(Flatten())\n",
    "\n",
    "\n",
    "\n",
    "# To Do: Add new dense layers along with Dropout etc. Add at least 2 dense layers -- you are free to pick the number of nodes. \n",
    "# Remember to finish with the classification head (i.e Dense layer with 1 node and sigmoid activation. )\n",
    "\n",
    "\n",
    "## To Do: Compile the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f733930",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## To do: print the model summary. Ensure that weights for the pre-trained model are frozen. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b45b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To do: Fit the model for 10 epochs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11f46785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To do: Evaluate model performance\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
